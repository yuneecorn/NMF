{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P : \n",
      "(5, 2)\n",
      "Q : \n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "R = [\n",
    "     [5,3,0,1],\n",
    "     [4,0,0,1],\n",
    "     [1,1,0,5],\n",
    "     [1,0,0,4],\n",
    "     [0,1,5,4],\n",
    "    ]\n",
    "\n",
    "R = np.array(R) # 평점이채워진 행렬 \n",
    "N = len(R)      # Item의수\n",
    "M = len(R[0])   # 유저의수 \n",
    "K = 2           # latent feature의 수\n",
    "\n",
    "\n",
    "np.random.seed(1)#고정된 행렬을 만들기 위한부분, 이부분이 없으면 P가 계속 바뀌게된다. \n",
    "P = np.random.rand(N,K) # Item 평가 행렬\n",
    "print \"P : \\n\", P.shape\n",
    "\n",
    "np.random.seed(2)\n",
    "Q = np.random.rand(M,K) # 유저의수 \n",
    "print \"Q : \\n\", Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementating Matrix Factorization \n",
    "steps : the maximum number of steps to perform the optimisation\n",
    "\n",
    "alpha : the learning rate\n",
    "\n",
    "beta  : the regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, alpha, steps=5000,  beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in xrange(steps):\n",
    "        # Stochastic Gradient Descent with weighted beta regularization(SGD-WR)\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0: # 0은 데이터가 없음(그 item에대한 리뷰 남긴게없음)을 의미\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])#prediction error\n",
    "                    for k in xrange(K):\n",
    "                        # gradient descent :weight update\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "                        \n",
    "        if step % 500 == 0 : \n",
    "            print \"step : \",step,\"\\n\", np.dot(P,Q) # np.dot(P,Q) = R hat\n",
    "\n",
    "        # Regularizied 에러 계산\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2) \n",
    "                    for k in xrange(K):\n",
    "                        #Regularization\n",
    "                        e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "        if e < 0.001: \n",
    "            print(e)\n",
    "            break\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0 \n",
      "[[ 0.20296966  0.54466713  0.41506942  0.5338031 ]\n",
      " [ 0.00884124  0.13245921  0.10062453  0.1880709 ]\n",
      " [ 0.06707004  0.12204015  0.09317115  0.08856389]\n",
      " [ 0.0912679   0.25387071  0.19343875  0.25360412]\n",
      " [ 0.18897971  0.45467355  0.34664197  0.41750375]]\n",
      "step :  500 \n",
      "[[ 2.49045997  1.70411655  2.24186489  2.84053588]\n",
      " [ 1.35187453  0.92642587  1.23334777  1.61524692]\n",
      " [ 1.80555219  1.2388137   1.66474611  2.2354851 ]\n",
      " [ 1.64550304  1.13014967  1.53068363  2.09766476]\n",
      " [ 2.76224475  1.89344089  2.5259766   3.32680862]]\n",
      "step :  1000 \n",
      "[[ 3.6074386   1.80081593  3.42820852  2.83782657]\n",
      " [ 2.45146845  1.22340763  2.40657425  2.11830793]\n",
      " [ 2.53246156  1.26204498  2.87373279  3.14520858]\n",
      " [ 2.18505082  1.08883264  2.49716218  2.75732522]\n",
      " [ 4.01022894  2.00010832  4.1978243   4.10959773]]\n",
      "step :  1500 \n",
      "[[ 4.54241362  2.11059361  3.91582859  1.79405869]\n",
      " [ 3.2073698   1.49384419  2.93289363  1.59914175]\n",
      " [ 1.82660564  0.88449755  3.259255    4.05519937]\n",
      " [ 1.58120355  0.76429496  2.75680677  3.3826046 ]\n",
      " [ 3.92097274  1.8489335   4.65540719  4.07236824]]\n",
      "step :  2000 \n",
      "[[ 5.06497268  2.41718622  4.17771214  1.12444414]\n",
      " [ 3.70616464  1.77147779  3.23444193  1.1428137 ]\n",
      " [ 1.25821684  0.63922062  3.5272165   4.76751186]\n",
      " [ 1.09415465  0.55339217  2.90806745  3.85879308]\n",
      " [ 3.57806735  1.73579984  4.76387213  4.06229378]]\n",
      "step :  2500 \n",
      "[[ 5.12185671  2.5736438   4.37148218  1.00219265]\n",
      " [ 3.85172641  1.93679288  3.450705    1.02921168]\n",
      " [ 1.14302343  0.59771166  3.76503505  4.9312477 ]\n",
      " [ 0.97160876  0.50691591  3.06198527  3.9581222 ]\n",
      " [ 3.25009743  1.65007099  4.79821623  4.05216867]]\n",
      "step :  3000 \n",
      "[[ 5.09545218  2.6745775   4.53514574  0.99154454]\n",
      " [ 3.89545407  2.04590619  3.62303126  1.00645681]\n",
      " [ 1.12869815  0.6153626   3.97785226  4.95661183]\n",
      " [ 0.94717526  0.51548801  3.22018122  3.97157544]\n",
      " [ 2.96617081  1.57371576  4.8182542   4.0475595 ]]\n",
      "step :  3500 \n",
      "[[ 5.06744794  2.74910797  4.67493645  0.99272135]\n",
      " [ 3.91587981  2.1261613   3.76669294  1.00018944]\n",
      " [ 1.12388816  0.64597457  4.17134794  4.96000249]\n",
      " [ 0.94264824  0.54037322  3.375014    3.9731594 ]\n",
      " [ 2.72238849  1.50378049  4.83468435  4.04627718]]\n",
      "step :  4000 \n",
      "[[ 5.04552835  2.80512757  4.7937381   0.99428598]\n",
      " [ 3.92930336  2.18728391  3.88814834  0.99777677]\n",
      " [ 1.11731019  0.67922755  4.34814235  4.96041762]\n",
      " [ 0.94351594  0.57093406  3.52222442  3.97310453]\n",
      " [ 2.5140215   1.44117092  4.84979616  4.04524863]]\n",
      "step :  4500 \n",
      "[[ 5.0288758   2.84712852  4.89410163  0.99554132]\n",
      " [ 3.93953518  2.23423834  3.99084383  0.99676088]\n",
      " [ 1.10889552  0.71190361  4.50911302  4.96081005]\n",
      " [ 0.94649961  0.60300965  3.65964186  3.9728836 ]\n",
      " [ 2.33617742  1.38615431  4.86402839  4.04334088]]\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0002\n",
    "nP, nQ = matrix_factorization(R, P, Q, K, alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.01629275  2.87852691  4.97827651  0.99659317]\n",
      " [ 3.94768814  2.27031369  4.07714135  0.99643295]\n",
      " [ 1.09961811  0.74256771  4.65450497  4.96151174]\n",
      " [ 0.95043828  0.63440334  3.78595081  3.9728005 ]\n",
      " [ 2.18446742  1.33835856  4.87730323  4.04049655]]\n"
     ]
    }
   ],
   "source": [
    "nR = np.dot(nP, nQ.T)\n",
    "print nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 3 0 1]\n",
      " [4 0 0 1]\n",
      " [1 1 0 5]\n",
      " [1 0 0 4]\n",
      " [0 1 5 4]]\n"
     ]
    }
   ],
   "source": [
    "print R #기존의 R "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
